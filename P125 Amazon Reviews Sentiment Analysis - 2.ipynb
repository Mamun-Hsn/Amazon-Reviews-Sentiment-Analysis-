{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb8ed4c",
   "metadata": {
    "id": "cdb8ed4c"
   },
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bbab7f",
   "metadata": {
    "id": "57bbab7f"
   },
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries\n",
    "import pandas as pd\n",
    "import  numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "ps = PorterStemmer()\n",
    "ls = WordNetLemmatizer()\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,auc,classification_report,recall_score,precision_score,precision_recall_curve,f1_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0e248",
   "metadata": {
    "id": "c3d0e248"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e4624",
   "metadata": {
    "id": "601e4624"
   },
   "outputs": [],
   "source": [
    "#Loading Dataset\n",
    "reviews=pd.read_csv('Preprocessed_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc729f",
   "metadata": {
    "id": "24bc729f",
    "outputId": "1854ecbe-8ee1-47a2-e7e2-063189ef44a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The media could not be loaded.\\n              ...</td>\n",
       "      <td>alexa cannot hear after she starts playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased this as a birthday gift for my 7 y...</td>\n",
       "      <td>i purchased this as a birthday gift for my yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The media could not be loaded.\\n              ...</td>\n",
       "      <td>here i am uploading video enjoy most idiotic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The media could not be loaded.\\n              ...</td>\n",
       "      <td>do not buy this product when i asked alexa th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its just one if the best deal i ever got on am...</td>\n",
       "      <td>its just one if the best deal i ever got on am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>OK OK</td>\n",
       "      <td>ok ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>I like alexa because this product is amazing. ...</td>\n",
       "      <td>i like alexa because this product is amazing m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>Voice recognition problem persist</td>\n",
       "      <td>voice recognition problem persist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>It's a nice product</td>\n",
       "      <td>it is a nice product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>Awesome ...i love Alexa..</td>\n",
       "      <td>awesome i love alexa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  \\\n",
       "0     The media could not be loaded.\\n              ...   \n",
       "1     I purchased this as a birthday gift for my 7 y...   \n",
       "2     The media could not be loaded.\\n              ...   \n",
       "3     The media could not be loaded.\\n              ...   \n",
       "4     Its just one if the best deal i ever got on am...   \n",
       "...                                                 ...   \n",
       "4152                                              OK OK   \n",
       "4153  I like alexa because this product is amazing. ...   \n",
       "4154                  Voice recognition problem persist   \n",
       "4155                                It's a nice product   \n",
       "4156                          Awesome ...i love Alexa..   \n",
       "\n",
       "                                                cleaned  \n",
       "0            alexa cannot hear after she starts playing  \n",
       "1     i purchased this as a birthday gift for my yea...  \n",
       "2      here i am uploading video enjoy most idiotic ...  \n",
       "3      do not buy this product when i asked alexa th...  \n",
       "4     its just one if the best deal i ever got on am...  \n",
       "...                                                 ...  \n",
       "4152                                              ok ok  \n",
       "4153  i like alexa because this product is amazing m...  \n",
       "4154                  voice recognition problem persist  \n",
       "4155                               it is a nice product  \n",
       "4156                              awesome i love alexa   \n",
       "\n",
       "[4157 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=reviews[['body','cleaned']]\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ca3fa",
   "metadata": {
    "id": "f29ca3fa",
    "outputId": "4037f7f6-ca16-4bed-b107-b970b93a9b48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body        0\n",
       "cleaned    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null entries\n",
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16c728",
   "metadata": {
    "id": "ac16c728",
    "outputId": "7d233979-68b5-41e0-8115-7d7a35da2faf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The media could not be loaded.\\n              ...</td>\n",
       "      <td>alexa cannot hear after she starts playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased this as a birthday gift for my 7 y...</td>\n",
       "      <td>i purchased this as a birthday gift for my yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The media could not be loaded.\\n              ...</td>\n",
       "      <td>here i am uploading video enjoy most idiotic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The media could not be loaded.\\n              ...</td>\n",
       "      <td>do not buy this product when i asked alexa th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its just one if the best deal i ever got on am...</td>\n",
       "      <td>its just one if the best deal i ever got on am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>OK OK</td>\n",
       "      <td>ok ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>I like alexa because this product is amazing. ...</td>\n",
       "      <td>i like alexa because this product is amazing m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>Voice recognition problem persist</td>\n",
       "      <td>voice recognition problem persist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>It's a nice product</td>\n",
       "      <td>it is a nice product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>Awesome ...i love Alexa..</td>\n",
       "      <td>awesome i love alexa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  \\\n",
       "0     The media could not be loaded.\\n              ...   \n",
       "1     I purchased this as a birthday gift for my 7 y...   \n",
       "2     The media could not be loaded.\\n              ...   \n",
       "3     The media could not be loaded.\\n              ...   \n",
       "4     Its just one if the best deal i ever got on am...   \n",
       "...                                                 ...   \n",
       "4152                                              OK OK   \n",
       "4153  I like alexa because this product is amazing. ...   \n",
       "4154                  Voice recognition problem persist   \n",
       "4155                                It's a nice product   \n",
       "4156                          Awesome ...i love Alexa..   \n",
       "\n",
       "                                                cleaned  \n",
       "0            alexa cannot hear after she starts playing  \n",
       "1     i purchased this as a birthday gift for my yea...  \n",
       "2      here i am uploading video enjoy most idiotic ...  \n",
       "3      do not buy this product when i asked alexa th...  \n",
       "4     its just one if the best deal i ever got on am...  \n",
       "...                                                 ...  \n",
       "4152                                              ok ok  \n",
       "4153  i like alexa because this product is amazing m...  \n",
       "4154                  voice recognition problem persist  \n",
       "4155                               it is a nice product  \n",
       "4156                              awesome i love alexa   \n",
       "\n",
       "[4122 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing null cells\n",
    "reviews=reviews.dropna(axis=0)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008b610",
   "metadata": {
    "id": "0008b610",
    "outputId": "2a0bec07-4b39-4ead-c141-d0feaa535534"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [alexa, cannot, hear, after, she, starts, play...\n",
       "1       [i, purchased, this, as, a, birthday, gift, fo...\n",
       "2       [here, i, am, uploading, video, enjoy, most, i...\n",
       "3       [do, not, buy, this, product, when, i, asked, ...\n",
       "4       [its, just, one, if, the, best, deal, i, ever,...\n",
       "                              ...                        \n",
       "4152                                             [ok, ok]\n",
       "4153    [i, like, alexa, because, this, product, is, a...\n",
       "4154               [voice, recognition, problem, persist]\n",
       "4155                           [it, is, a, nice, product]\n",
       "4156                            [awesome, i, love, alexa]\n",
       "Name: cleaned, Length: 4122, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the sentence\n",
    "df_cleaned=reviews.cleaned.str.split()\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd08996",
   "metadata": {
    "id": "9bd08996"
   },
   "outputs": [],
   "source": [
    "#performing stemming and lemmatization after stopwords removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_stemmed = df_cleaned.apply(lambda x: [ps.stem(word) for word in x if word not in stop_words])\n",
    "df_lemmatized = df_cleaned.apply(lambda x: [ls.lemmatize(word) for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be400a",
   "metadata": {
    "id": "e9be400a"
   },
   "outputs": [],
   "source": [
    "df_stemmed = df_stemmed.apply(lambda x: ' '.join(x))\n",
    "df_lemmatized = df_lemmatized.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d8e98",
   "metadata": {
    "id": "698d8e98"
   },
   "outputs": [],
   "source": [
    "reviews['Stemmed_text']=df_stemmed.to_frame()\n",
    "reviews['Lemmatized_text']=df_lemmatized.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae13001",
   "metadata": {
    "id": "0ae13001",
    "outputId": "07f34f5f-5e07-447a-dc76-b0ec0092c3dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>Stemmed_text</th>\n",
       "      <th>Lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The media could not be loaded.\\n              ...</td>\n",
       "      <td>alexa cannot hear after she starts playing</td>\n",
       "      <td>alexa cannot hear start play</td>\n",
       "      <td>alexa cannot hear start playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased this as a birthday gift for my 7 y...</td>\n",
       "      <td>i purchased this as a birthday gift for my yea...</td>\n",
       "      <td>purchas birthday gift year old son sinc sibl t...</td>\n",
       "      <td>purchased birthday gift year old son since sib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The media could not be loaded.\\n              ...</td>\n",
       "      <td>here i am uploading video enjoy most idiotic ...</td>\n",
       "      <td>upload video enjoy idiot devic everi bought ne...</td>\n",
       "      <td>uploading video enjoy idiotic device every bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The media could not be loaded.\\n              ...</td>\n",
       "      <td>do not buy this product when i asked alexa th...</td>\n",
       "      <td>buy product ask alexa kashmir part countri sai...</td>\n",
       "      <td>buy product asked alexa kashmir part country s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its just one if the best deal i ever got on am...</td>\n",
       "      <td>its just one if the best deal i ever got on am...</td>\n",
       "      <td>one best deal ever got amazon purchas watt wip...</td>\n",
       "      <td>one best deal ever got amazon purchased watt w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>OK OK</td>\n",
       "      <td>ok ok</td>\n",
       "      <td>ok ok</td>\n",
       "      <td>ok ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>I like alexa because this product is amazing. ...</td>\n",
       "      <td>i like alexa because this product is amazing m...</td>\n",
       "      <td>like alexa product amaz mani problem solv alex...</td>\n",
       "      <td>like alexa product amazing many problem solve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>Voice recognition problem persist</td>\n",
       "      <td>voice recognition problem persist</td>\n",
       "      <td>voic recognit problem persist</td>\n",
       "      <td>voice recognition problem persist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>It's a nice product</td>\n",
       "      <td>it is a nice product</td>\n",
       "      <td>nice product</td>\n",
       "      <td>nice product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>Awesome ...i love Alexa..</td>\n",
       "      <td>awesome i love alexa</td>\n",
       "      <td>awesom love alexa</td>\n",
       "      <td>awesome love alexa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4122 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  \\\n",
       "0     The media could not be loaded.\\n              ...   \n",
       "1     I purchased this as a birthday gift for my 7 y...   \n",
       "2     The media could not be loaded.\\n              ...   \n",
       "3     The media could not be loaded.\\n              ...   \n",
       "4     Its just one if the best deal i ever got on am...   \n",
       "...                                                 ...   \n",
       "4152                                              OK OK   \n",
       "4153  I like alexa because this product is amazing. ...   \n",
       "4154                  Voice recognition problem persist   \n",
       "4155                                It's a nice product   \n",
       "4156                          Awesome ...i love Alexa..   \n",
       "\n",
       "                                                cleaned  \\\n",
       "0            alexa cannot hear after she starts playing   \n",
       "1     i purchased this as a birthday gift for my yea...   \n",
       "2      here i am uploading video enjoy most idiotic ...   \n",
       "3      do not buy this product when i asked alexa th...   \n",
       "4     its just one if the best deal i ever got on am...   \n",
       "...                                                 ...   \n",
       "4152                                              ok ok   \n",
       "4153  i like alexa because this product is amazing m...   \n",
       "4154                  voice recognition problem persist   \n",
       "4155                               it is a nice product   \n",
       "4156                              awesome i love alexa    \n",
       "\n",
       "                                           Stemmed_text  \\\n",
       "0                          alexa cannot hear start play   \n",
       "1     purchas birthday gift year old son sinc sibl t...   \n",
       "2     upload video enjoy idiot devic everi bought ne...   \n",
       "3     buy product ask alexa kashmir part countri sai...   \n",
       "4     one best deal ever got amazon purchas watt wip...   \n",
       "...                                                 ...   \n",
       "4152                                              ok ok   \n",
       "4153  like alexa product amaz mani problem solv alex...   \n",
       "4154                      voic recognit problem persist   \n",
       "4155                                       nice product   \n",
       "4156                                  awesom love alexa   \n",
       "\n",
       "                                        Lemmatized_text  \n",
       "0                       alexa cannot hear start playing  \n",
       "1     purchased birthday gift year old son since sib...  \n",
       "2     uploading video enjoy idiotic device every bou...  \n",
       "3     buy product asked alexa kashmir part country s...  \n",
       "4     one best deal ever got amazon purchased watt w...  \n",
       "...                                                 ...  \n",
       "4152                                              ok ok  \n",
       "4153  like alexa product amazing many problem solve ...  \n",
       "4154                  voice recognition problem persist  \n",
       "4155                                       nice product  \n",
       "4156                                 awesome love alexa  \n",
       "\n",
       "[4122 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a7406",
   "metadata": {
    "id": "9c9a7406"
   },
   "outputs": [],
   "source": [
    "df=reviews[['Stemmed_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619621c",
   "metadata": {
    "id": "2619621c"
   },
   "outputs": [],
   "source": [
    "#finding polarity from textblob\n",
    "from textblob import TextBlob\n",
    "df['polarity']=(round(reviews['Stemmed_text'].apply(lambda x:TextBlob(x).sentiment.polarity),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de7f2e",
   "metadata": {
    "id": "56de7f2e",
    "outputId": "2b948a02-4912-4334-fb47-fe43e7408793"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stemmed_text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alexa cannot hear start play</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purchas birthday gift year old son sinc sibl t...</td>\n",
       "      <td>0.1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>upload video enjoy idiot devic everi bought ne...</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buy product ask alexa kashmir part countri sai...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one best deal ever got amazon purchas watt wip...</td>\n",
       "      <td>0.3238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>ok ok</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>like alexa product amaz mani problem solv alex...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>voic recognit problem persist</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>nice product</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>awesom love alexa</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Stemmed_text  polarity\n",
       "0                          alexa cannot hear start play    0.0000\n",
       "1     purchas birthday gift year old son sinc sibl t...    0.1881\n",
       "2     upload video enjoy idiot devic everi bought ne...    0.2000\n",
       "3     buy product ask alexa kashmir part countri sai...    0.0000\n",
       "4     one best deal ever got amazon purchas watt wip...    0.3238\n",
       "...                                                 ...       ...\n",
       "4152                                              ok ok    0.5000\n",
       "4153  like alexa product amaz mani problem solv alex...    0.0000\n",
       "4154                      voic recognit problem persist    0.0000\n",
       "4155                                       nice product    0.6000\n",
       "4156                                  awesom love alexa    0.5000\n",
       "\n",
       "[4122 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955bdb2c",
   "metadata": {
    "id": "955bdb2c"
   },
   "outputs": [],
   "source": [
    "pol=[]\n",
    "for i in df.polarity:\n",
    "    if i<0:\n",
    "        pol.append('negative')\n",
    "    elif i>0:\n",
    "        pol.append('positive')\n",
    "    else:\n",
    "        pol.append('neutral')\n",
    "df['sentiment']=pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7eb10c",
   "metadata": {
    "id": "be7eb10c",
    "outputId": "1fad50be-ff46-4eac-f3dc-961434bcd966"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stemmed_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alexa cannot hear start play</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purchas birthday gift year old son sinc sibl t...</td>\n",
       "      <td>0.1881</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>upload video enjoy idiot devic everi bought ne...</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buy product ask alexa kashmir part countri sai...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one best deal ever got amazon purchas watt wip...</td>\n",
       "      <td>0.3238</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>worst experi alexa warranti get product amazon...</td>\n",
       "      <td>-0.4429</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>buy product pleas keep point mind need amazon ...</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>use alexa dot nd gen today gift dot rd gen dad...</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>work beauti bought link entir hous frequent gr...</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>use get bulb worth make echo dot roughli dolla...</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Stemmed_text  polarity sentiment\n",
       "0                       alexa cannot hear start play    0.0000   neutral\n",
       "1  purchas birthday gift year old son sinc sibl t...    0.1881  positive\n",
       "2  upload video enjoy idiot devic everi bought ne...    0.2000  positive\n",
       "3  buy product ask alexa kashmir part countri sai...    0.0000   neutral\n",
       "4  one best deal ever got amazon purchas watt wip...    0.3238  positive\n",
       "5  worst experi alexa warranti get product amazon...   -0.4429  negative\n",
       "6  buy product pleas keep point mind need amazon ...    0.3100  positive\n",
       "7  use alexa dot nd gen today gift dot rd gen dad...    0.1946  positive\n",
       "8  work beauti bought link entir hous frequent gr...    0.0500  positive\n",
       "9  use get bulb worth make echo dot roughli dolla...    0.1121  positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a4250a",
   "metadata": {
    "id": "30a4250a"
   },
   "outputs": [],
   "source": [
    "df.to_csv('for_ann.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e3e74",
   "metadata": {
    "id": "985e3e74",
    "outputId": "afad769a-d7cb-4644-cec6-97ca166b8029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    2773\n",
       "neutral     1074\n",
       "negative     275\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f890542",
   "metadata": {
    "id": "6f890542"
   },
   "outputs": [],
   "source": [
    "df['target'] = df['sentiment'].replace({'positive':2,'neutral':1,'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692b88c",
   "metadata": {
    "id": "8692b88c"
   },
   "outputs": [],
   "source": [
    "#vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(df['Stemmed_text'].values.astype('U'))\n",
    "y=df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26e770",
   "metadata": {
    "id": "9d26e770",
    "outputId": "fa4f6446-e093-4119-e9b6-dd9ce243d677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       2\n",
       "3       1\n",
       "4       2\n",
       "       ..\n",
       "4152    2\n",
       "4153    1\n",
       "4154    1\n",
       "4155    2\n",
       "4156    2\n",
       "Name: target, Length: 4122, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774867fc",
   "metadata": {
    "id": "774867fc",
    "outputId": "923d5005-230f-4e65-fe18-4161f3f75742"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=0., max_df=1.0)\n",
    "X = vect.fit_transform(df['Stemmed_text'])\n",
    "print(pd.DataFrame(X.A, columns=vect.get_feature_names()).to_string())\n",
    "df = pd.DataFrame(X.toarray().transpose(), index = vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efdd5cf",
   "metadata": {
    "id": "4efdd5cf",
    "outputId": "db78c511-beb4-4632-fa34-eaba1699849a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4112</th>\n",
       "      <th>4113</th>\n",
       "      <th>4114</th>\n",
       "      <th>4115</th>\n",
       "      <th>4116</th>\n",
       "      <th>4117</th>\n",
       "      <th>4118</th>\n",
       "      <th>4119</th>\n",
       "      <th>4120</th>\n",
       "      <th>4121</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aap</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aapl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaya</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yur</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zomato</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3688 rows × 4122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9     ...  4112  \\\n",
       "aa         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "aap        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "aapl       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "aaya       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "ab         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "yur        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "zero       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "zomato     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "zoom       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "zyan       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "        4113  4114  4115  4116  4117  4118  4119  4120  4121  \n",
       "aa         0     0     0     0     0     0     0     0     0  \n",
       "aap        0     0     0     0     0     0     0     0     0  \n",
       "aapl       0     0     0     0     0     0     0     0     0  \n",
       "aaya       0     0     0     0     0     0     0     0     0  \n",
       "ab         0     0     0     0     0     0     0     0     0  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "yur        0     0     0     0     0     0     0     0     0  \n",
       "zero       0     0     0     0     0     0     0     0     0  \n",
       "zomato     0     0     0     0     0     0     0     0     0  \n",
       "zoom       0     0     0     0     0     0     0     0     0  \n",
       "zyan       0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[3688 rows x 4122 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#document term matrix\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b91b79",
   "metadata": {
    "id": "63b91b79"
   },
   "outputs": [],
   "source": [
    "#Splitting for train and test data\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9974e",
   "metadata": {
    "id": "45a9974e"
   },
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484f702",
   "metadata": {
    "id": "5484f702",
    "outputId": "61fa4952-48dd-4cdf-e3ec-7049cb0c9b7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7490909090909091"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "review_classifier_model=MultinomialNB()\n",
    "review_classifier_model.fit(X_train,y_train)\n",
    "y_pred=review_classifier_model.predict(X_test)\n",
    "np.mean(y_pred==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204510bb",
   "metadata": {
    "id": "204510bb"
   },
   "outputs": [],
   "source": [
    "nb_acc=round(accuracy_score(y_test,y_pred),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12e886",
   "metadata": {
    "id": "fb12e886"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9189323",
   "metadata": {
    "id": "d9189323",
    "outputId": "127830f7-e99f-4afe-d71b-9ef160bad67e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9357575757575758"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model=LogisticRegression(random_state=1)\n",
    "lr_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=lr_model.predict(X_test)\n",
    "np.mean(y_pred==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de4297e",
   "metadata": {
    "id": "6de4297e"
   },
   "outputs": [],
   "source": [
    "lr_acc=round(accuracy_score(y_test,y_pred),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0357e",
   "metadata": {
    "id": "d7b0357e"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811fb057",
   "metadata": {
    "id": "811fb057",
    "outputId": "f49c1f26-4877-4593-be9b-ba91a88380d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8690909090909091"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model=DecisionTreeClassifier(random_state=1,max_depth=15)\n",
    "dt_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=dt_model.predict(X_test)\n",
    "np.mean(y_pred==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478066d9",
   "metadata": {
    "id": "478066d9"
   },
   "outputs": [],
   "source": [
    "dt_acc=round(accuracy_score(y_test,y_pred),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701214c9",
   "metadata": {
    "id": "701214c9"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380903b2",
   "metadata": {
    "id": "380903b2",
    "outputId": "48e1b396-2f45-4212-f402-d322910441a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9151515151515152"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model=RandomForestClassifier(random_state=1)\n",
    "rf_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=rf_model.predict(X_test)\n",
    "np.mean(y_pred==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5250100",
   "metadata": {
    "id": "e5250100"
   },
   "outputs": [],
   "source": [
    "rf_acc=round(accuracy_score(y_test,y_pred),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7654d797",
   "metadata": {
    "id": "7654d797"
   },
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7456d",
   "metadata": {
    "id": "c9c7456d",
    "outputId": "aecceac9-58fd-44d0-d0f1-b89661c94e41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9018181818181819"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_model=AdaBoostClassifier(random_state=1)\n",
    "ada_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=ada_model.predict(X_test)\n",
    "np.mean(y_pred==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647eb4f",
   "metadata": {
    "id": "9647eb4f"
   },
   "outputs": [],
   "source": [
    "ada_acc=round(accuracy_score(y_test,y_pred),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52a9f5",
   "metadata": {
    "id": "8e52a9f5"
   },
   "source": [
    "### SVM with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09af7cb",
   "metadata": {
    "id": "b09af7cb"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=1)\n",
    "\n",
    "svc_param = ({'C':[0.02,0.2,2,8],\n",
    "             'kernel':['linear', 'rbf', 'sigmoid'],\n",
    "             'gamma':['scale', 'auto']\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ec938",
   "metadata": {
    "id": "1d7ec938",
    "outputId": "b7ee3331-7e9a-4f37-f51d-d4c5fd5c1ef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END .............C=0.02, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV 2/5] END .............C=0.02, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV 3/5] END .............C=0.02, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV 4/5] END .............C=0.02, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV 5/5] END .............C=0.02, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV 1/5] END ................C=0.02, gamma=scale, kernel=rbf; total time=   0.7s\n",
      "[CV 2/5] END ................C=0.02, gamma=scale, kernel=rbf; total time=   0.8s\n",
      "[CV 3/5] END ................C=0.02, gamma=scale, kernel=rbf; total time=   0.7s\n",
      "[CV 4/5] END ................C=0.02, gamma=scale, kernel=rbf; total time=   0.7s\n",
      "[CV 5/5] END ................C=0.02, gamma=scale, kernel=rbf; total time=   0.7s\n",
      "[CV 1/5] END ............C=0.02, gamma=scale, kernel=sigmoid; total time=   0.5s\n",
      "[CV 2/5] END ............C=0.02, gamma=scale, kernel=sigmoid; total time=   0.6s\n",
      "[CV 3/5] END ............C=0.02, gamma=scale, kernel=sigmoid; total time=   0.6s\n",
      "[CV 4/5] END ............C=0.02, gamma=scale, kernel=sigmoid; total time=   0.5s\n",
      "[CV 5/5] END ............C=0.02, gamma=scale, kernel=sigmoid; total time=   0.5s\n",
      "[CV 1/5] END ..............C=0.02, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV 2/5] END ..............C=0.02, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV 3/5] END ..............C=0.02, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV 4/5] END ..............C=0.02, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV 5/5] END ..............C=0.02, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV 1/5] END .................C=0.02, gamma=auto, kernel=rbf; total time=   0.4s\n",
      "[CV 2/5] END .................C=0.02, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 3/5] END .................C=0.02, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 4/5] END .................C=0.02, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 5/5] END .................C=0.02, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 1/5] END .............C=0.02, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 2/5] END .............C=0.02, gamma=auto, kernel=sigmoid; total time=   0.4s\n",
      "[CV 3/5] END .............C=0.02, gamma=auto, kernel=sigmoid; total time=   0.4s\n",
      "[CV 4/5] END .............C=0.02, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 5/5] END .............C=0.02, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 1/5] END ..............C=0.2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV 2/5] END ..............C=0.2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV 3/5] END ..............C=0.2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV 4/5] END ..............C=0.2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV 5/5] END ..............C=0.2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV 1/5] END .................C=0.2, gamma=scale, kernel=rbf; total time=   0.6s\n",
      "[CV 2/5] END .................C=0.2, gamma=scale, kernel=rbf; total time=   0.6s\n",
      "[CV 3/5] END .................C=0.2, gamma=scale, kernel=rbf; total time=   0.7s\n",
      "[CV 4/5] END .................C=0.2, gamma=scale, kernel=rbf; total time=   0.7s\n",
      "[CV 5/5] END .................C=0.2, gamma=scale, kernel=rbf; total time=   0.7s\n",
      "[CV 1/5] END .............C=0.2, gamma=scale, kernel=sigmoid; total time=   0.5s\n",
      "[CV 2/5] END .............C=0.2, gamma=scale, kernel=sigmoid; total time=   0.5s\n",
      "[CV 3/5] END .............C=0.2, gamma=scale, kernel=sigmoid; total time=   0.5s\n",
      "[CV 4/5] END .............C=0.2, gamma=scale, kernel=sigmoid; total time=   0.5s\n",
      "[CV 5/5] END .............C=0.2, gamma=scale, kernel=sigmoid; total time=   0.4s\n",
      "[CV 1/5] END ...............C=0.2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV 2/5] END ...............C=0.2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV 3/5] END ...............C=0.2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV 4/5] END ...............C=0.2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV 5/5] END ...............C=0.2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV 1/5] END ..................C=0.2, gamma=auto, kernel=rbf; total time=   0.6s\n",
      "[CV 2/5] END ..................C=0.2, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 3/5] END ..................C=0.2, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 4/5] END ..................C=0.2, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 5/5] END ..................C=0.2, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 1/5] END ..............C=0.2, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 2/5] END ..............C=0.2, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 3/5] END ..............C=0.2, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 4/5] END ..............C=0.2, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 5/5] END ..............C=0.2, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 1/5] END ................C=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV 2/5] END ................C=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV 3/5] END ................C=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV 4/5] END ................C=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV 5/5] END ................C=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV 1/5] END ...................C=2, gamma=scale, kernel=rbf; total time=   0.8s\n",
      "[CV 2/5] END ...................C=2, gamma=scale, kernel=rbf; total time=   0.8s\n",
      "[CV 3/5] END ...................C=2, gamma=scale, kernel=rbf; total time=   0.9s\n",
      "[CV 4/5] END ...................C=2, gamma=scale, kernel=rbf; total time=   0.7s\n",
      "[CV 5/5] END ...................C=2, gamma=scale, kernel=rbf; total time=   0.7s\n",
      "[CV 1/5] END ...............C=2, gamma=scale, kernel=sigmoid; total time=   0.2s\n",
      "[CV 2/5] END ...............C=2, gamma=scale, kernel=sigmoid; total time=   0.2s\n",
      "[CV 3/5] END ...............C=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV 4/5] END ...............C=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV 5/5] END ...............C=2, gamma=scale, kernel=sigmoid; total time=   0.2s\n",
      "[CV 1/5] END .................C=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV 2/5] END .................C=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV 3/5] END .................C=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV 4/5] END .................C=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV 5/5] END .................C=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV 1/5] END ....................C=2, gamma=auto, kernel=rbf; total time=   0.4s\n",
      "[CV 2/5] END ....................C=2, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 3/5] END ....................C=2, gamma=auto, kernel=rbf; total time=   0.4s\n",
      "[CV 4/5] END ....................C=2, gamma=auto, kernel=rbf; total time=   0.4s\n",
      "[CV 5/5] END ....................C=2, gamma=auto, kernel=rbf; total time=   0.4s\n",
      "[CV 1/5] END ................C=2, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 2/5] END ................C=2, gamma=auto, kernel=sigmoid; total time=   0.4s\n",
      "[CV 3/5] END ................C=2, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 4/5] END ................C=2, gamma=auto, kernel=sigmoid; total time=   0.5s\n",
      "[CV 5/5] END ................C=2, gamma=auto, kernel=sigmoid; total time=   0.4s\n",
      "[CV 1/5] END ................C=8, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV 2/5] END ................C=8, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV 3/5] END ................C=8, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV 4/5] END ................C=8, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV 5/5] END ................C=8, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV 1/5] END ...................C=8, gamma=scale, kernel=rbf; total time=   0.6s\n",
      "[CV 2/5] END ...................C=8, gamma=scale, kernel=rbf; total time=   0.6s\n",
      "[CV 3/5] END ...................C=8, gamma=scale, kernel=rbf; total time=   0.6s\n",
      "[CV 4/5] END ...................C=8, gamma=scale, kernel=rbf; total time=   0.6s\n",
      "[CV 5/5] END ...................C=8, gamma=scale, kernel=rbf; total time=   0.6s\n",
      "[CV 1/5] END ...............C=8, gamma=scale, kernel=sigmoid; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...............C=8, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV 3/5] END ...............C=8, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV 4/5] END ...............C=8, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV 5/5] END ...............C=8, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV 1/5] END .................C=8, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV 2/5] END .................C=8, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV 3/5] END .................C=8, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV 4/5] END .................C=8, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV 5/5] END .................C=8, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV 1/5] END ....................C=8, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 2/5] END ....................C=8, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 3/5] END ....................C=8, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 4/5] END ....................C=8, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV 5/5] END ....................C=8, gamma=auto, kernel=rbf; total time=   0.4s\n",
      "[CV 1/5] END ................C=8, gamma=auto, kernel=sigmoid; total time=   0.4s\n",
      "[CV 2/5] END ................C=8, gamma=auto, kernel=sigmoid; total time=   0.4s\n",
      "[CV 3/5] END ................C=8, gamma=auto, kernel=sigmoid; total time=   0.4s\n",
      "[CV 4/5] END ................C=8, gamma=auto, kernel=sigmoid; total time=   0.4s\n",
      "[CV 5/5] END ................C=8, gamma=auto, kernel=sigmoid; total time=   0.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(random_state=1),\n",
       "             param_grid={'C': [0.02, 0.2, 2, 8], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'rbf', 'sigmoid']},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search CV:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_cv = GridSearchCV(svc, param_grid=svc_param, cv=5,verbose=5)\n",
    "grid_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed9f89",
   "metadata": {
    "id": "91ed9f89",
    "outputId": "ffb3d926-ecdd-4cc9-b259-3fb850fb5bce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2, 'gamma': 'scale', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441c4fe",
   "metadata": {
    "id": "6441c4fe",
    "outputId": "d01d51c5-7a73-44d7-df23-2b6ad42a3d53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9563636363636364"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svc_pred = grid_cv.predict(X_test)\n",
    "np.mean(grid_svc_pred==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ecee5",
   "metadata": {
    "id": "c74ecee5"
   },
   "outputs": [],
   "source": [
    "svc=SVC(C= 2, gamma= 'scale', kernel= 'linear')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred=svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad6e788",
   "metadata": {
    "id": "8ad6e788",
    "outputId": "63a95f05-d1bd-4726-8817-d94d0790c0ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78        55\n",
      "           1       0.91      0.98      0.95       230\n",
      "           2       0.99      0.97      0.98       540\n",
      "\n",
      "    accuracy                           0.96       825\n",
      "   macro avg       0.91      0.89      0.90       825\n",
      "weighted avg       0.96      0.96      0.96       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd096a1",
   "metadata": {
    "id": "3bd096a1"
   },
   "outputs": [],
   "source": [
    "svc_acc=round(accuracy_score(y_test,y_pred),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc49b11",
   "metadata": {
    "id": "1fc49b11"
   },
   "outputs": [],
   "source": [
    "data=[['Multinomial Naive Bayes',nb_acc],['Logistic Regression',lr_acc],['Decision Tree',dt_acc],['Random Forest',rf_acc],\n",
    "      ['Ada Boost',ada_acc],['Support Vector Classifier',svc_acc]]\n",
    "\n",
    "df=pd.DataFrame(data,columns=['Model','test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7183fc",
   "metadata": {
    "id": "1f7183fc",
    "outputId": "34b8c907-8c78-4e72-b9f8-c2b24906a146"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.7491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>0.9018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.9564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  test_accuracy\n",
       "0    Multinomial Naive Bayes         0.7491\n",
       "1        Logistic Regression         0.9358\n",
       "2              Decision Tree         0.8691\n",
       "3              Random Forest         0.9152\n",
       "4                  Ada Boost         0.9018\n",
       "5  Support Vector Classifier         0.9564"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3187eb7",
   "metadata": {
    "id": "a3187eb7",
    "outputId": "2ccd9886-e9f8-4709-9d33-5719f7119e99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 40   8   7]\n",
      " [  5 225   0]\n",
      " [  3  13 524]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e674af",
   "metadata": {
    "id": "84e674af",
    "outputId": "68968ff8-3eba-4d24-9b3e-a53fb3abd681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78        55\n",
      "           1       0.91      0.98      0.95       230\n",
      "           2       0.99      0.97      0.98       540\n",
      "\n",
      "    accuracy                           0.96       825\n",
      "   macro avg       0.91      0.89      0.90       825\n",
      "weighted avg       0.96      0.96      0.96       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a5d63a",
   "metadata": {
    "id": "b7a5d63a"
   },
   "source": [
    "### Manually Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e888acb",
   "metadata": {
    "id": "4e888acb",
    "outputId": "f66fc917-343f-4b9b-9326-9fdb3da20fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a review for which sentiment needs to be predicted:\n",
      "Good Product but worst delivery\n"
     ]
    }
   ],
   "source": [
    "test=input('Please enter a review for which sentiment needs to be predicted:\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8c51c",
   "metadata": {
    "id": "8fd8c51c"
   },
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"couldn\\'t\", \"could not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "def cleaning(text):\n",
    "    corpus = []\n",
    "    text = decontracted(text)\n",
    "    text = text.lower()                              #lowering the text\n",
    "    text = re.sub(r'#\\S+','',text)                   #Remove the hyper link\n",
    "    text = re.sub('[^a-z]',' ',text)              #Remove the character other than alphabet\n",
    "    text = text.split()\n",
    "    text=[ps.stem(word) for word in text if word not in stopwords.words('english')]\n",
    "    text=' '.join(text)\n",
    "    corpus.append(text)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24214262",
   "metadata": {
    "id": "24214262",
    "outputId": "aa2f1ca9-aa71-44de-ccde-07f23c42899e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_cleaned=cleaning(test)\n",
    "type(review_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390aa48",
   "metadata": {
    "id": "4390aa48",
    "outputId": "6edfa0d7-8a9c-40b3-8c8f-776803228464"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good product worst deliveri']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205715d",
   "metadata": {
    "id": "5205715d",
    "outputId": "fb1e176f-d442-47c3-91bd-bb00fa4f94d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "df=cv.transform(review_cleaned).toarray()\n",
    "pred=svc.predict(df)\n",
    "label=pred[0]\n",
    "\n",
    "if label==2:\n",
    "    print('Positive')\n",
    "elif label==0:\n",
    "    print('Negative')\n",
    "else:\n",
    "    print('Neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eb8f27",
   "metadata": {
    "id": "97eb8f27"
   },
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19caa326",
   "metadata": {
    "id": "19caa326"
   },
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "dump(cv,open('pickle/countvectorizer.pkl','wb'))\n",
    "dump(svc,open('pickle/model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c681919",
   "metadata": {
    "id": "4c681919"
   },
   "source": [
    "### Predicting new review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de0db0",
   "metadata": {
    "id": "14de0db0"
   },
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"couldn\\'t\", \"could not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "def cleaning(text):\n",
    "    corpus = []\n",
    "    text = decontracted(text)\n",
    "    text = text.lower()                              #lowering the text\n",
    "    text = re.sub(r'#\\S+','',text)                   #Remove the hyper link\n",
    "    text = re.sub('[^a-z]',' ',text)              #Remove the character other than alphabet\n",
    "    text = text.split()\n",
    "    text=[ps.stem(word) for word in text if word not in stopwords.words('english')]\n",
    "    text=' '.join(text)\n",
    "    corpus.append(text)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74276a",
   "metadata": {
    "id": "9e74276a"
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "def predict(input_review):\n",
    "    vectorizer=load(open('pickle/countvectorizer.pkl','rb'))\n",
    "    classifier=load(open('pickle/model.pkl','rb'))\n",
    "    clean_text=cleaning(input_review)\n",
    "    vec_clean_text=vectorizer.transform(clean_text)\n",
    "    vec_array=vec_clean_text.toarray()\n",
    "    prediction=classifier.predict(vec_array)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea17117",
   "metadata": {
    "id": "9ea17117",
    "outputId": "72371788-dd2d-4202-937b-77d6aaafca78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Product\n"
     ]
    }
   ],
   "source": [
    "input_review=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1d185",
   "metadata": {
    "id": "baf1d185"
   },
   "outputs": [],
   "source": [
    "prediction = predict(input_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888806ef",
   "metadata": {
    "id": "888806ef",
    "outputId": "661f357e-17a3-4b37-c7da-e82cb30ce5ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "if prediction==2:\n",
    "    print('Positive')\n",
    "elif prediction==0:\n",
    "    print('Negative')\n",
    "else:\n",
    "    print('Neutral')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "P125 Amazon Reviews Sentiment Analysis - 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
